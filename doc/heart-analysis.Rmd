```{r instructions, message=FALSE, warning=FALSE}
### steps:

#    -   English: 
#    -   English: Visualise the relationship between DEATH, GLUCOSE and SYSBP.
#    -   English: Form an initial hypothesis of what to look for when doing the classification.
#    -   English: On the training set, fit a (multiple) logistic regression model.
#    -   English: Compute the misclassification rates on the test set.
#    -   English: Compute the confusion matrix on the test set.
#    -   English: Visualise your fitted classification models, e.g., by plotting the decision boundaries in the GLUCOSE-SYSBP-plane.
#    -   English: Make a comment or observation regarding goodness of fit.
#    -   English: Modify your logistic regression to classify as "risky" if the risk is higher than 10%.
 #   -   English: Repeat the tasks of question c) (misclassification rates, confusion matrix, visualisation) with the modified threshold.
#    -   English: Compare the performance of logistic regression and discriminant analysis on this classification problem.
#    -   English: Identify strong risk factors from this dataset and communicate your results.

```



```{r a1-prepare-model-data, message=FALSE, warning=FALSE}

heart_selected <-  select(heart_df, where(is.numeric)) |>
  select(-any_of(c("RANDID", "PERIOD", "TIMECVD", "TIMEMIFC", "TIMECHD",
                   "TIMEDTH", "TIME", "TIMEMI", "TIMESTRK", "TIMESCHD",
                   "TIMEAP"))) |>
  select(any_of(c("AGE", "SEX", "SYSBP", "DIABP", "GLUCOSE", "DIABETES",
                  "BMI", "educ", "CVD")))

heart_clean <-  drop_na(heart_selected,GLUCOSE, SYSBP, CVD)

pretty_df(heart_clean, title = "heart_clean for  Logistic Regression", max_rows = 10)
```

# English: Split the dataset into a training set (80%) and a test set (20%)

```{r a2-split-data, message=FALSE, warning=FALSE}

set.seed(82171165) # for reproducibility

#  80:20 split idx
n <- nrow(heart_clean)
size <- 0.8 * n
nSeq <- seq_len(n)
train_idx <- sample(nSeq, size)

#  training and test sets
heart_train <- heart_clean[ train_idx, ]
heart_test  <- heart_clean[-train_idx, ]

```


```{r a2-fit-logistic-mode, message=FALSE, warning=FALSE}
# Fit logistic regression models on training and test sets
logit_train <- glm(CVD ~ GLUCOSE + SYSBP, data = heart_train, family = binomial)
logit_test  <- glm(CVD ~ GLUCOSE + SYSBP, data = heart_test, family = binomial)
logit_train
summary(logit_train)
logit_test
summary(logit_test)
```

```{r logistic-coefficients-flextable, message=FALSE, warning=FALSE}
library(flextable)
library(dplyr)

# Extract coefficients and format as strings
extract_stat <- function(model, label) {
  coefs <- summary(model)$coefficients
  data.frame(
    Statistic     = c("Estimate", "z value", "Pr(>|z|)"),
    X.Intercept.  = round(c(coefs[1,1], coefs[1,3], coefs[1,4]), 3),
    GLUCOSE       = round(c(coefs[2,1], coefs[2,3], coefs[2,4]), 3),
    SYSBP         = round(c(coefs[3,1], coefs[3,3], coefs[3,4]), 3),
    Group         = label,
    stringsAsFactors = FALSE
  )
}

# Combine Train and Test rows
tbl <- bind_rows(
  extract_stat(logit_train, "Train"),
  extract_stat(logit_test,  "Test")
)

# Render flextable (no interpretation column)
ft <- flextable(tbl) |>
  set_caption("Coefficient and Dataset") |>
  autofit() |>
  fontsize(size = 11, part = "all") |>
  align(align = "center", part = "all") |>
  theme_booktabs() |>
  padding(padding = 4, part = "all") |>
  line_spacing(space = 1.1) |>
  border(i = 3, border.bottom = fp_border(width = 2))  # thick line after training rows

ft

```


```{r logistic-fit-metrics-flextable, message=FALSE, warning=FALSE}
library(flextable)

# Extract training metrics
null_dev_train  <- round(logit_train$null.deviance, 1)
df_null_train   <- logit_train$df.null
resid_dev_train <- round(logit_train$deviance, 1)
df_resid_train  <- logit_train$df.residual
aic_train       <- round(logit_train$aic, 1)

# Extract test metrics
null_dev_test   <- round(logit_test$null.deviance, 1)
df_null_test    <- logit_test$df.null
resid_dev_test  <- round(logit_test$deviance, 1)
df_resid_test   <- logit_test$df.residual
aic_test        <- round(logit_test$aic, 1)

# Construct data frame
fit_tbl <- data.frame(
  Metric = c("Null Deviance", "Residual Deviance", "AIC"),
  Training.Set = c(
    paste0(null_dev_train, " (", df_null_train, " df)"),
    paste0(resid_dev_train, " (", df_resid_train, " df)"),
    aic_train
  ),
  Test.Set = c(
    paste0(null_dev_test, " (", df_null_test, " df)"),
    paste0(resid_dev_test, " (", df_resid_test, " df)"),
    aic_test
  ),
  stringsAsFactors = FALSE
)

# Render with flextable
flextable(fit_tbl) |>
  set_caption("Logistic Regression Fit Metrics for Training and Test Sets") |>
  autofit() |>
  fontsize(size = 11, part = "all") |>
  align(align = "center", part = "all") |>
  theme_booktabs() |>
  padding(padding = 4, part = "all") |>
  line_spacing(space = 1.1)
```


 

 


 
 
 
 
 
 


```{r a3a-decision-boundary-grid, message=FALSE, warning=FALSE}
# A3. Decision Boundary Grid
grid_vals <- expand.grid(
  GLUCOSE = seq(min(heart_test$GLUCOSE, na.rm = TRUE), max(heart_test$GLUCOSE, na.rm = TRUE), length.out = 100),
  SYSBP   = seq(min(heart_test$SYSBP, na.rm = TRUE), max(heart_test$SYSBP, na.rm = TRUE), length.out = 100)
)
grid_vals$prob <- predict(logit_train, newdata = grid_vals, type = "response")
```

```{r a3b-logistic-decision-plot, message=FALSE, warning=FALSE}
# A4. ggplot for Logistic Regression
ggph_logistic <- ggplot(heart_test, aes(x = GLUCOSE, y = SYSBP, colour = as.factor(CVD))) +
  geom_point(alpha = 0.6) +
  stat_contour(data = grid_vals, aes(z = prob), breaks = 0.5, colour = "black") +
  labs(title = "Logistic Regression: GLUCOSE vs SYSBP", colour = "CVD") +
  theme_minimal()
print(ggph_logistic)
```

```{r a4a-model-evaluation, message=FALSE, warning=FALSE}
# A5. Model Evaluation
heart_test$prob <- predict(logit_test, type = "response")
heart_test$pred <- ifelse(heart_test$prob > 0.5, 1, 0)

# Accuracy calculation
accuracy <- mean(heart_test$pred == heart_test$CVD)
cat(sprintf("\nModel Accuracy (Threshold = 0.5): %.2f\n", accuracy))

# Optional confusion matrix
conf_mat <- table(Predicted = heart_test$pred, Actual = heart_test$CVD)
print(conf_mat)
```

```{r a5a-qda-model, message=FALSE, warning=FALSE}
# A5. QDA model (token)
heart_qda_df <- heart_df |>
  select(GLUCOSE, SYSBP, CVD) |>
  na.omit()

qda_model <- qda(CVD ~ GLUCOSE + SYSBP, data = heart_qda_df)
```

```{r a5b-qda-boundary, message=FALSE, warning=FALSE}

grid_qda <- expand.grid(
  GLUCOSE = seq(min(heart_qda_df$GLUCOSE), max(heart_qda_df$GLUCOSE), length.out = 100),
  SYSBP = seq(min(heart_qda_df$SYSBP), max(heart_qda_df$SYSBP), length.out = 100)
)
grid_qda$class <- predict(qda_model, newdata = grid_qda)$class

ggph_qda_boundary <- ggplot(heart_qda_df, aes(x = GLUCOSE, y = SYSBP, color = as.factor(CVD))) +
  geom_point(alpha = 0.6) +
  geom_tile(data = grid_qda, aes(x = GLUCOSE, y = SYSBP, fill = class), 
            alpha = 0.2, inherit.aes = FALSE) +
  labs(title = "QDA Decision Boundary (Token)", fill = "Predicted") +
  theme_minimal()

```

```{r a7-knn-model-token-—-define-function-and-apply, message=FALSE, warning=FALSE}

# A7. kNN model (token) — Define function and apply
knn_predict <- function(train, test, cl, k = 5) {
  class::knn(train = train, test = test, cl = cl, k = k)
}
knn_classes <- knn_predict(
  train = heart_qda_df[, c("GLUCOSE", "SYSBP")],
  test = grid_qda[, c("GLUCOSE", "SYSBP")],
  cl = heart_qda_df$CVD,
  k = 5
)
grid_qda$knn <- knn_classes

```

```{r a8-knn-decision-boundary-token-ggplot, message=FALSE, warning=FALSE}

# A8. kNN decision boundary (token ggplot)
ggph_knn_boundary <- ggplot(heart_qda_df, aes(x = GLUCOSE, y = SYSBP, color = as.factor(CVD))) +
  geom_point(alpha = 0.6) +
  geom_tile(
    data = grid_qda, 
    aes(x = GLUCOSE, y = SYSBP, fill = knn), 
    alpha = 0.2, 
    inherit.aes = FALSE
  ) +
  labs(title = "kNN Decision Boundary (Token)", fill = "Predicted") +
  theme_minimal()

print(ggph_knn_boundary)


```

```{r a9-placeholder-for-additional-metrics, message=FALSE, warning=FALSE}

# A9. Placeholder for additional metrics
qda_pred <- predict(qda_model)$class
qda_accuracy <- mean(qda_pred == heart_qda_df$CVD)
cat(sprintf("QDA Accuracy (Token): %.2f\n", qda_accuracy))

knn_accuracy <- mean(knn_classes == heart_qda_df$CVD[1:length(knn_classes)])
cat(sprintf("kNN Accuracy (Token): %.2f\n", knn_accuracy))




```
