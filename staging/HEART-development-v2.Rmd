---
title:    "STAT462 Assignment 2"
author: 
  -       "David Ewing (82171165)"
  -       "Xia Yu      (62380486)"
date:     "`r Sys.Date()`"
output:   
  pdf_document:
    latex_engine: xelatex
    fig_caption:     true
    number_sections: true
    toc:             true
    keep_tex:        true
    fig_crop:        false         # disable pdfcrop 
    includes:
      in_header: ../doc/fonts.tex
fontsize: 11pt
geometry: margin=1in

output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    
mainfont: Arial
fontsize: 10pt
---
```{r setup, include=FALSE}
# This chunk was set up with the aid of ChatGPT.
# The intent is to load updates quietly thus not
# spending undue time with the logistics of getting 
# setup. 


#---------------- knitr::opts_chunk ---------------------------
#---------------- knitr::opts_chunk ---------------------------

knitr::opts_chunk$set(
  dev.args = list(
    png = list(type = "cairo")
    ),
  results = "markup",   # default("markup") "asis" "hide"	"hold"	"show"
  echo    = TRUE,      # Whether the code is shown
  eval    = TRUE,       # Whether the code is executed
  message = FALSE,      # Whether messages are printed
  warning = FALSE,     # Whether warnings are printed
  error   = FALSE       # Whether errors stop execution
  )

#---------------- loading libraries ---------------------------
#---------------- loading libraries ---------------------------

# Load configuration for reproducibility and preferred CRAN mirror
options(repos = c(CRAN = "https://cran.stat.auckland.ac.nz/"))

#library(conflicted) # before any other

# Required packages
required_packages <- c(
  "caret",         # Model training utilities
  "class",         # kNN 
  "cowplot",       # Plot composition
  "dplyr",         # Data wrangling
  "flextable",     # Summary tables
  "GGally",        # Pair plots
  "ggplot2",       # Core plotting
  "glmnet",        # Regularised regression
  "glue",          # glue
  "patchwork",      # âœ… for ggplot grid layouts
  "rsample",         # initial_split
  "kableExtra",    # Table formatting
  "knitr",         # Inline rendering
  "MASS",          # LDA/QDA and logistic
  "officer",       # Word/PDF table styling (used by flextable)
  "skimr",         # Data summaries
  "tree",
  "tidyverse",     # Core data science packages
  "tibble"         # Modern data frames
)
for (pkg in required_packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg)
  }
  library(pkg, character.only = TRUE)
}

#---------------- conflict_prefer ------------------------------
#---------------- conflict_prefer ------------------------------
library(conflicted)
if ("conflicted" %in% loadedNamespaces()) {
  try(conflict_prefer("filter", "dplyr"), silent = TRUE)
  try(conflict_prefer("select", "dplyr"), silent = TRUE)
}

```

```


```{r deebug, include=FALSE}
#---------------- DEEBUG functions -----------------------------
#---------------- DEEBUG functions -----------------------------


options(browser = NULL)           # Disable   browser()
options(browser = utils::browser) # reinstate browser()


# ---- Pretty Data-frame with Type Summary and Preview ---------
# ---- Pretty Data-frame with Type Summary and Preview ---------
# works with flextable;  

pretty_df <- function(df,
                      title    = NULL,
                      fontsize = 10,
                      n        = 5) {
  if (!is.data.frame(df)) {
    stop("Input must be a data frame")
  }

  # Optional row slicing
  if (n > 0) df <- head(df, n)
  if (n < 0) df <- tail(df, abs(n))

  ft <- flextable::flextable(df)

  if (!is.null(title)) {
    ft <- flextable::set_caption(ft, title)
  }

  ft <- ft |>
    flextable::fontsize(size = fontsize, part = "all") |>
    flextable::align(align = "center", part = "all") |>
    flextable::theme_booktabs() |>
    flextable::bold(i = 1, part = "header") |>
    flextable::padding(padding = 5, part = "all")

  return(ft)
}



pretty_df <- function(df,
                      title    = NULL,
                      fontsize = 10,
                      n        = 5) {
  if (!is.data.frame(df)) {
    stop("Input must be a data frame")
  }

  # Optional row slicing
  if (n > 0) df <- head(df, n)
  if (n < 0) df <- tail(df, abs(n))

  ft <- flextable::flextable(df)

  if (!is.null(title)) {
    ft <- flextable::set_caption(ft, title)
  }

  ft <- ft |>
    flextable::fontsize(size = fontsize, part = "all") |>
    flextable::align(align = "center", part = "all") |>
    flextable::theme_booktabs() |>
    flextable::bold(i = 1, part = "header") |>
    flextable::padding(padding = 5, part = "all") |>
    flextable::autofit()

  return(ft)
}




# ---- Pretty Summary  with Type Summary and Preview ------
# ---- Pretty Summary  with Type Summary and Preview ------
# works with flextable; provides a summary of column types
# and a preview

pretty_summary <- \(df) {   # works with flextable 
  ft = select(df, where(is.numeric)) |>
    summarise(
      across(
        everything(),
        .fns = list(
          Mean     = \(x) mean(x, na.rm = TRUE),
          Median   = \(x) median(x, na.rm = TRUE),
          Min      = \(x) min(x, na.rm = TRUE),
          Max      = \(x) max(x, na.rm = TRUE),
          IQR      = \(x) IQR(x, na.rm = TRUE),
          nNA      = \(x) sum(is.na(x))
        )
      )
    ) |>
    pivot_longer(
      cols = everything(),
      names_to = c("Variable", ".value"),
      names_sep = "_"
    ) |>
    mutate(across(where(is.numeric), round, 2)) |>
    flextable() |>
    set_header_labels(
      Variable = "Feature",
      Mean     = "Mean",
      Median   = "Median",
      Min      = "Min",
      Max      = "Max",
      IQR      = "Interquartile Range",
      nNA      = "Missing Values"
    ) |>
    autofit() |>
    theme_vanilla()
  }


# ---- Pretty csv_read with Type Summary and Preview ------
# ---- Pretty csv_read with Type Summary and Preview ------ 
# works with flextable; provides a summary of column types
# and a preview

pretty_read_csv <- \(path, n = 5, col_names = TRUE, show_col_types = FALSE) {   
  df <- readr::read_csv(path, show_col_types = FALSE, col_names = col_names)
  df <- as.data.frame(df)
  ft <- pretty_df(df,glue("CSV:{path}"))
  return(list(df=df,ft=ft))
}

# ---- Pretty Excel Reader with Type Summary and Preview ----
# ---- Pretty Excel Reader with Type Summary and Preview ----
# Requires: readxl, flextable, purrr

pretty_read_xlsx <- \(path, sheet = 1, col_names = TRUE, n = 0) {
  # Read Excel file
  df <- readxl::read_excel(path, sheet = sheet, col_names = col_names)
  df <- as.data.frame(df)  
  # Extract column types
  types <- purrr::map_chr(df, typeof)
  type_df <- data.frame(
                Column = names(df), 
                Type = types,
                stringsAsFactors = FALSE
                )

  ft = pretty_df(type_df,glue("XLSX Column Types:{path}"))
 
  return(list(df=df,ft=ft))
}




# ---- Pretty Excel Reader with Type Summary and Preview ----
# ---- Pretty Excel Reader with Type Summary and Preview ----
# Requires: readxl, flextable, purrr

pretty_ggplot <- \(plot, title = "ggplot Summary") {
  if (!inherits(plot, "gg")) stop("Input must be a ggplot object.")

  # Extract key components
  plot_data <- tryCatch(plot$data, error = function(e) NULL)
  geoms <- sapply(plot$layers, function(layer) class(layer$geom)[1])
  mappings <- plot$mapping
  
  # Pull out global aesthetics as strings
  global_aes  <- names(mappings)
  global_vals <- sapply(mappings, function(x) rlang::expr_text(x))

  # Additional metadata
  p_title <- plot$labels$title %||% title %||% ""
  x_lab   <- plot$labels$x %||% ""
  y_lab   <- plot$labels$y %||% ""
  colour_lab <- plot$labels$colour %||% plot$labels$color %||% ""

  # Build a metadata data frame
  df <- data.frame(
    Component = c(
                "Title",
                "X Axis",
                "Y Axis", 
                "Colour Legend",
                "Geoms",
                global_aes),
    Value     = c(
                p_title, 
                x_lab,    
                y_lab,    
                colour_lab,
                paste(geoms , collapse = ","),
                global_vals),
    stringsAsFactors = FALSE
  )

  ft = pretty_df(df)
  return(ft)
  }

 
# ---- Pretty glm model with Type Summary and Preview -------
# ---- Pretty glm model with Type Summary and Preview -------
# Requires: readxl, flextable, purrr

pretty_glm <- function(model) {
  if (!inherits(model, "glm")) {
    stop("pretty_glm() expects a glm object.")
    return(NULL)
  }

  tryCatch({
    Metric <- c(
      "Formula",
      "AIC",
      "Null deviance",
      "Residual deviance",
      "Component names",
      "Model class"
    )

    Value <- c(
      deparse(formula(model)),
      AIC(model),
      model$null.deviance,
      model$deviance,
      paste(names(model), collapse = ", "),
      paste(class(model), collapse = ", ")
    )

    df <- data.frame(Metric, Value, stringsAsFactors = FALSE)
    return (df)
    #pretty_df(df, title = "Fit Statistics")
    
  },
  error = function(e) {
    cat("Error in pretty_glm():", conditionMessage(e), "\n")
    return(NULL)
  })
}



pretty_split_df <- function(df,
                            cols = 6,
                            title = NULL,
                            fontsize = 10,
                            n = 5) {
  if (!is.data.frame(df)) {
    stop(cat("\\textit{Object is not a data frame:}", deparse(df)))
  }

  title <- if (is.null(title)) deparse(substitute(df)) else title
  df_show <- if (n > 0) head(df, n) else if (n < 0) tail(df, abs(n)) else df
  col_groups <- split(names(df_show), ceiling(seq_along(df_show) / cols))

  # Return a named list of flextables created by pretty_df
  ft_list <- lapply(seq_along(col_groups), function(i) {
    subdf <- df_show[, col_groups[[i]], drop = FALSE]
    pretty_df(
      subdf,
      title = paste0(title, " (", i, ")"),
      fontsize = fontsize,
      n = n
    )
  })

  names(ft_list) <- paste0(
    title,
    " (",
    seq_along(ft_list),
    ")"
  )

  return(ft_list)
}




```



```{r wsb-global-model-utils}
# --- Model Evaluation Utilities ---

model_boolean_eval <- function(model, pred_class, actual_class, train_data, threshold = 0.5) {
  pvals <- broom::tidy(model)$p.value
  sig_all <- all(pvals < 0.05)

  test_acc <- mean(pred_class == actual_class)
  base_acc <- max(prop.table(table(actual_class)))
  better_than_random <- test_acc > 0.5

  better_than_baseline_mild     <- (test_acc - base_acc) >= 0.01
  better_than_baseline_moderate <- (test_acc - base_acc) >= 0.015
  better_than_baseline_strong   <- (test_acc - base_acc) >= 0.02
  real_world_gain               <- (test_acc - base_acc) >= 0.05

  train_probs <- predict(model, newdata = train_data, type = "response")
  train_class <- ifelse(train_probs > threshold, 1, 0)
  train_acc <- mean(train_class == train_data$DEATH)
  well_generalised <- abs(train_acc - test_acc) < 0.05

  list(
    sig_all = sig_all,
    test_acc = test_acc,
    base_acc = base_acc,
    better_than_random = better_than_random,
    better_than_mild = better_than_baseline_mild,
    better_than_moderate = better_than_baseline_moderate,
    better_than_strong = better_than_baseline_strong,
    well_generalised = well_generalised,
    real_world_gain = real_world_gain
  )
}

summarise_boolean_eval <- function(eval_list) {
  data.frame(
    Question = c(
      "Statistically significant?",
      "Better than random?",
      "Better than majority guess? (â‰¥ 0.01)",
      "Better than majority guess? (â‰¥ 0.015)",
      "Better than majority guess? (â‰¥ 0.02)",
      "Well-generalised?",
      "Real-world useful?"
    ),
    Result = unlist(c(
      eval_list$sig_all,
      eval_list$better_than_random,
      eval_list$better_than_mild,
      eval_list$better_than_moderate,
      eval_list$better_than_strong,
      eval_list$well_generalised,
      eval_list$real_world_gain
    )),
    Justification = c(
      "all(pvals < 0.05)",
      "test_acc > 0.5",
      "(test_acc - base_acc) >= 0.01",
      "(test_acc - base_acc) >= 0.015",
      "(test_acc - base_acc) >= 0.02",
      "abs(train_acc - test_acc) < 0.05",
      "(test_acc - base_acc) >= 0.05"
    ),
    stringsAsFactors = FALSE
  )
}


#Convert probabilities to labelled factor predictions
predict_classes <- function(probs, threshold = 0.5) {
  factor(ifelse(probs > threshold, 1, 0), levels = c(0, 1), labels = c("LIVE", "DEAD"))
}

# 2. Create a labelled confusion matrix from predicted and actual class labels
make_conf_matrix <- function(pred_class, actual_class) {
  table(
    Predicted = factor(pred_class, levels = c("LIVE", "DEAD")),
    Actual    = factor(actual_class, levels = c("LIVE", "DEAD"))
  )
}

# 3. Compute performance metrics from a 2x2 labelled confusion matrix
# Returns: misclassification, accuracy, precision, recall, F1
eval_conf_matrix <- function(cmtx) {
  tp <- cmtx["DEAD", "DEAD"]
  tn <- cmtx["LIVE", "LIVE"]
  fp <- cmtx["DEAD", "LIVE"]
  fn <- cmtx["LIVE", "DEAD"]
  total <- sum(cmtx)

  if (total == 0 || any(is.na(c(tp, tn, fp, fn)))) return(rep(NA, 5))

  accuracy  <- (tp + tn) / total
  precision <- if ((tp + fp) > 0) tp / (tp + fp) else NA
  recall    <- if ((tp + fn) > 0) tp / (tp + fn) else NA
  f1        <- if (!is.na(precision) && !is.na(recall) && (precision + recall) > 0)
                 2 * precision * recall / (precision + recall) else NA
  misclass  <- 1 - accuracy

  c(misclass, accuracy, precision, recall, f1)
}

# 4. Convert a vector of named metrics into a summary data frame
summarise_metrics <- function(metrics_vec) {
  metric_names <- c("Misclassification Rate", "Accuracy", "Precision (DEAD)", "Recall (DEAD)", "F1 Score (DEAD)")
  data.frame(Metric = metric_names, Value = round(metrics_vec, 3), stringsAsFactors = FALSE)
}
```




```{r load-and-test-split, results='hide'}
# Load heart and colour datasets from zip

# Set base directory
# Assign named paths based on filename match
# load the dataframes via pretty_read_csv 
# preview structure
unzip_dir <- "../data/unzipped"
zip_path  <- "../data/data_assignment_2.zip"
csv_files <- unzip(zip_path, list = TRUE)$Name  # Extract filenames from the zip
target_paths <- file.path(unzip_dir, csv_files)

idx_color   <- grep("color", csv_files)
idx_heart   <- grep("heart", csv_files)
path_colour <- target_paths[idx_color]
path_heart  <- target_paths[idx_heart]
 
heart_list  <- pretty_read_csv(path_heart, col_names = TRUE)
colour_list <- pretty_read_csv(path_colour, col_names = TRUE)
   
heart_df = heart_list$df
heart_ft = heart_list$ft 
                                                         
colour_df = colour_list$df
colour_ft = colour_list$ft 


foo <- pretty_split_df(heart_df)

render_flextables <- function(ft_list) {
  for (ft in foo) {
    invisible(print(knitr::knit_print(ft)))
    }
  }

render_flextables(foo)
```




```{r  wsb-step-01}
cat("### Split the dataset into a training set (80%) and a test set (20%)
")

# keep original

h_vars <- c("DEATH", "GLUCOSE", "SYSBP", "AGE")
h_clean <- heart_df |>
  select(all_of(h_vars)) |>
  drop_na() |>
  mutate(DEATH = as.factor(DEATH))

# Stratified split : DEATH
set.seed(82171165)
h_split   <- initial_split(h_clean, prop = 0.8, strata = DEATH)
h_train   <- training(h_split)
h_test    <- testing(h_split)

# For visualisation only: relabel  "LIVE" and "DEAD"
levels = c(0, 1)
labels = c("LIVE", "DEAD")


hp_clean <- h_clean |>
  mutate(DEATH = factor(DEATH, levels = levels, labels = labels))
hp_train <- h_train |>
  mutate(DEATH = factor(DEATH, levels = levels, labels = labels))
hp_test <- h_test |>
  mutate(DEATH = factor(DEATH, levels = levels, labels = labels))

h_actual_class  <- h_test$DEATH        # true observed values
hp_actual_class <- hp_test$DEATH

```
### Visualise the relationship between DEATH, GLUCOSE and SYSBP

<!-- Inserted from WBS: wsb-step-02 -->
```{r wsb-step-02}
cat("### Visualise the relationship between DEATH, GLUCOSE and SYSBP\n")

ggp_relationship <- ggplot(hp_clean, aes(x = GLUCOSE, y = SYSBP, colour = DEATH)) +
  geom_point(alpha = 0.6) +
  labs(title = "DEATH vs GLUCOSE and SYSBP", x = "GLUCOSE", y = "SYSBP")

# 1. Distribution of SYSBP
ggp_sysbp <- ggplot(hp_test, aes(x = SYSBP)) +
  geom_histogram(bins = 40, fill = "steelblue", colour = "white") +
  labs(title = "Distribution of SYSBP", x = "SYSBP", y = "Count")

# 2. Distribution of GLUCOSE
ggp_glucose <- ggplot(hp_test, aes(x = GLUCOSE)) +
  geom_histogram(bins = 40, fill = "darkorange", colour = "white") +
  labs(title = "Distribution of GLUCOSE", x = "GLUCOSE", y = "Count")

# 3â€“6. Combination of linear/log axis scales
base <- ggplot(hp_test, aes(x = GLUCOSE, y = SYSBP)) +
  geom_point(alpha = 0.6) +
  labs(title = NULL, x = "GLUCOSE", y = "SYSBP")

p_lin_lin <- base + ggtitle("Linear X / Linear Y")
p_log_lin <- base + scale_x_log10() + ggtitle("Log X / Linear Y")
p_lin_log <- base + scale_y_log10() + ggtitle("Linear X / Log Y")
p_log_log <- base + scale_x_log10() + scale_y_log10() + ggtitle("Log X / Log Y")

# Combine 4 into a grid
p_combined <- (p_lin_lin | p_log_lin) / (p_lin_log | p_log_log)

# Output all plots
print(ggp_relationship)
print(ggp_sysbp)
print(ggp_glucose)
print(p_combined)

pretty_ggplot(ggp_relationship, title = "Relationship: DEATH vs GLUCOSE and SYSBP")
pretty_ggplot(ggp_sysbp, title = "Distribution of SYSBP")
pretty_ggplot(ggp_glucose, title = "Distribution of GLUCOSE")
pretty_ggplot(p_lin_lin, title = "Linear X / Linear Y")
pretty_ggplot(p_log_lin, title = "Log X / Linear Y")
pretty_ggplot(p_lin_log, title = "Linear X / Log Y")
pretty_ggplot(p_log_log, title = "Log X / Log Y")
pretty_ggplot(p_combined, title = "Log/Linear Scale Comparison Grid")

```

### Form an initial hypothesis of what to look for when doing the classification


<!-- Inserted from WBS: wsb-step-03 -->
```{r  wsb-step-03}
print("We hypothesise that high GLUCOSE and high SYSBP are associated with higher DEATH risk.")
```

### Fit a logistic regression model on the training set


<!-- Inserted from WBS: wsb-step-04 -->
```{r  wsb-step-04}
hp_glm_metrx <- glm(DEATH ~ GLUCOSE + SYSBP + AGE, data = hp_train, family = "binomial")
pretty_glm(hp_glm_metrx)
```







### Compute the misclassification rate on the test set


```{r wsb-step-05.1}

```

 


### Compute the confusion matrix on the test set
```{r wsb-step-06.1}
cat("### Logistic Regression Evaluation (Threshold = 0.50)\n")



hp_pred_probs <- predict(hp_glm_metrx, newdata = hp_test, type = "response")
hp_pred_class <- predict_classes(hp_pred_probs, threshold = 0.5)
hp_actual_class <- factor(hp_test$DEATH, levels = c("LIVE", "DEAD"))

hp_cmtx_test <- make_conf_matrix(hp_pred_class, hp_actual_class)
hp_metrics <- eval_conf_matrix(hp_cmtx_test)
hp_mtrx_df <- summarise_metrics(hp_metrics)

hp_cmtx_df <- as.data.frame.matrix(hp_cmtx_test)
hp_cmtx_df <- cbind(Predicted = rownames(hp_cmtx_df), hp_cmtx_df)
rownames(hp_cmtx_df) <- NULL

print(pretty_df(hp_cmtx_df, title = "Confusion Matrix (Threshold = 0.50)"))
print(pretty_df(hp_mtrx_df, title = "Logistic Regression Performance (Threshold = 0.50)"))
```
# 6. Predict on test set and evaluate
```{r step-06-predict-eval}
# Predict using QDA 
# Add predicted class to test data
# Define custom confusion matrix function
# Create the confusion matrix
c_qda_pred <- predict(c_qda_train, newdata = c_test)
c_test$.pred_class <- c_qda_pred$class
c_conf_mat <- make_conf_matrix(c_test$.pred_class, c_test$colour)

# View it
print(c_conf_mat)


<!-- Inserted from WBS: wsb-step-07 -->
```{r  wsb-step-07}

ggplot(hp_test, aes(x = GLUCOSE, y = SYSBP, colour = hp_pred_class)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Logistic Regression Decision Boundary (approx)",
    colour = "Predicted"
  )

```

### Comment on the goodness of fit

### Supporting numeric metrics for evaluation criteria


<!-- Inserted from WBS: wsb-step-09 -->
```{r  wsb-step-09}
hp_pred_class_10 <- ifelse(hp_pred_probs > 0.1, 1, 0)
hp_pred_class_10 <- factor(hp_pred_class_10, levels = c(0, 1), labels = c("LIVE", "DEAD"))
```

### Recompute misclassification, confusion, and visualisation for 10% threshold
# Confusion Matrix (Threshold = 0.10)


<!-- Inserted from WBS: wsb-step-10 -->
```{r  wsb-step-10}
#hp_misclass_rate_10 <- mean(hp_pred_class_10 != hp_actual_class)
#hp_cmtx_10 = table(Predicted = h_pred_class_10, Actual = h_actual_class)
```

### Compare logistic regression and discriminant analysis
```{r wsb-step-10.1}
cat("### Logistic Regression Evaluation (Threshold = 0.10)\n")

hp_pred_probs <- predict(hp_glm_metrx, newdata = hp_test, type = "response")
hp_pred_class_10 <- predict_classes(hp_pred_probs, threshold = 0.10)
hp_actual_class <- factor(hp_test$DEATH, levels = c("LIVE", "DEAD"))

hp_cmtx_test_10 <- make_conf_matrix(hp_pred_class_10, hp_actual_class)
hp_metrics_10 <- eval_conf_matrix(hp_cmtx_test_10)
hp_mtrx_df_10 <- summarise_metrics(hp_metrics_10)

hp_cmtx_df_10 <- as.data.frame.matrix(hp_cmtx_test_10)
hp_cmtx_df_10 <- cbind(Predicted = rownames(hp_cmtx_df_10), hp_cmtx_df_10)
rownames(hp_cmtx_df_10) <- NULL

print(pretty_df(hp_cmtx_df_10, title = "Confusion Matrix (Threshold = 0.10)"))
print(pretty_df(hp_mtrx_df_10, title = "Logistic Regression Performance (Threshold = 0.10)"))
```


<!-- Inserted from WBS: wsb-step-11 -->
### QDA Evaluation
<!-- Inserted from WBS: wsb-step-11.1 -->
```{r wsb-step-11.1}
cat("### QDA Evaluation\n")

# Build QDA model using labeled data
hp_qda_model <- qda(DEATH ~ GLUCOSE + SYSBP + AGE, data = hp_train)

# Predict posterior probabilities and classes
qda_output <- predict(hp_qda_model, newdata = hp_test)
hp_qda_pred_probs <- qda_output$posterior[, "DEAD"]
hp_qda_pred_class <- predict_classes(hp_qda_pred_probs, threshold = 0.5)

# Define actual classes
hp_actual_class <- factor(hp_test$DEATH, levels = c("LIVE", "DEAD"))

# Confusion matrix and metrics
hp_cmtx_qda <- make_conf_matrix(hp_qda_pred_class, hp_actual_class)
hp_metrics_qda <- eval_conf_matrix(hp_cmtx_qda)
hp_mtrx_df_qda <- summarise_metrics(hp_metrics_qda)

# Format confusion matrix for display
hp_cmtx_df_qda <- as.data.frame.matrix(hp_cmtx_qda)
hp_cmtx_df_qda <- cbind(Predicted = rownames(hp_cmtx_df_qda), hp_cmtx_df_qda)
rownames(hp_cmtx_df_qda) <- NULL

# Print results
print(pretty_df(hp_cmtx_df_qda, title = "QDA Confusion Matrix"))
print(pretty_df(hp_mtrx_df_qda, title = "QDA Model Performance"))

```
 

### Visualise the decision boundaries of the fitted QDA model in a suitable way

<!-- Inserted from WBS: wsb-step-12 -->
```{r wsb-step-12}
print("Visualise the decision boundaries of the fitted QDA model in a suitable way.")

# A simple visualisation by predicted class
hp_qda_probs <- predict(hp_qda_model, newdata = hp_test)$posterior[, 2]
hp_qda_pred_class <- predict_classes(hp_qda_probs, threshold = 0.5)


ggp_qda_boundary <- ggplot(hp_test, aes(x = GLUCOSE, y = SYSBP, colour = hp_qda_pred_class)) +
  geom_point(alpha = 0.5) +
  labs(title = "QDA Decision Boundary (approx)", colour = "Predicted")



print(ggp_qda_boundary)
```

### Identify strong risk factors and communicate results


<!-- Inserted from WBS: wsb-step-13 -->
### Fit a tree-based model to the training set
<!-- Inserted from WBS: wsb-step-13 -->
```{r wsb-step-13}
cat("### Fit a Tree-Based Model to the Training Set\n")

# Fit classification tree to hpl_train
hpl_tree_model <- tree(DEATH ~ GLUCOSE + SYSBP + AGE, data = hpl_train)

# Optional: Display summary of the model
print(summary(hpl_tree_model))

# Optional: Visualise the tree
plot(hpl_tree_model)
text(hpl_tree_model, pretty = 0)

```

### Tree-Based or Optional Model Evaluation
```{r wsb-step-13.1}
cat("### Tree-Based or Optional Model Evaluation\n")

# Generate predicted probabilities and classes
hpl_pred_probs  <- predict(hpl_tree_model, newdata = hpl_test, type = "response")
hpl_pred_class  <- predict_classes(hpl_pred_probs[, "DEAD"], threshold = 0.5)
hpl_actual_class <- factor(hpl_test$DEATH, levels = c("LIVE", "DEAD"))

# Build confusion matrix
hpl_cmtx  <- make_conf_matrix(hpl_pred_class, hpl_actual_class)
hpl_metrics <- eval_conf_matrix(hpl_cmtx)
hpl_mtrx_df <- summarise_metrics(hpl_metrics)

# Format for display
hpl_cmtx_df <- as.data.frame.matrix(hpl_cmtx)
hpl_cmtx_df <- cbind(Predicted = rownames(hpl_cmtx_df), hpl_cmtx_df)
rownames(hpl_cmtx_df) <- NULL

# Print both confusion matrix and metrics
print(pretty_df(hpl_cmtx_df, title = "Tree-Based Model Confusion Matrix"))
print(pretty_df(hpl_mtrx_df, title = "Tree-Based Model Performance"))

```


```
